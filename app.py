import sys
import os
from flask import Flask, render_template, request, jsonify
from groq import Groq
from dotenv import load_dotenv

# ==========================================
# ğŸ› ï¸ é—œéµä¿®å¾©ï¼šè§£æ±º Windows ç·¨ç¢¼éŒ¯èª¤ (UnicodeError)
# ==========================================
# é€™è¡ŒæŒ‡ä»¤æœƒå¼·è¿« Python ä½¿ç”¨ UTF-8 ä¾†å°å‡ºæ–‡å­—
# å¿…é ˆæ”¾åœ¨æ‰€æœ‰ print ä¹‹å‰ï¼Œé€™æ¨£çµ‚ç«¯æ©Ÿé¡¯ç¤ºä¸­æ–‡æˆ– Emoji å°±ä¸æœƒå´©æ½°
try:
    sys.stdout.reconfigure(encoding='utf-8')
except AttributeError:
    # é‡å°æŸäº›ç‰¹æ®Šçš„ Python ç‰ˆæœ¬åšç›¸å®¹æ€§è™•ç†
    pass

# 1. è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# ==========================================
# ğŸ”‘ è¨­å®š Groq API Key
# ==========================================
# è«‹ç¢ºä¿æ‚¨çš„ .env æª”æ¡ˆè£¡é¢æœ‰é€™ä¸€è¡Œï¼šGROQ_API_KEY=gsk_xxxx...
api_key = os.getenv("GROQ_API_KEY")

# æª¢æŸ¥ Key æ˜¯å¦å­˜åœ¨
if not api_key:
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GROQ_API_KEYï¼Œè«‹æª¢æŸ¥ .env æª”æ¡ˆï¼")
    # ç‚ºäº†é˜²æ­¢ç¨‹å¼ç›´æ¥æ›æ‰ï¼Œé€™è£¡è¨­ä¸€å€‹å‡çš„
    api_key = "gsk_error"
else:
    print("âœ… æˆåŠŸè®€å– API Keyï¼(Groq æ¨¡å¼)")

# å»ºç«‹ Groq é€£ç·šå®¢æˆ¶ç«¯
try:
    client = Groq(api_key=api_key)
except Exception as e:
    print(f"âŒ Groq å®¢æˆ¶ç«¯å»ºç«‹å¤±æ•—: {e}")
    client = None

app = Flask(__name__)

# ==========================================
# ğŸ’– AI äººè¨­è¨­å®šï¼šæš–å¿ƒ (Llama 3.3 é«˜æ™ºå•†ç‰ˆ)
# ==========================================
SYSTEM_PROMPT = """
ä½ ç¾åœ¨çš„åå­—å«åšã€æš–å¿ƒã€(SoulMate)ã€‚
ä½ æ˜¯ä¸€ä½æ€§æ ¼æº«æŸ”ã€å……æ»¿åŒç†å¿ƒçš„ AI é™ªä¼´è€…ã€‚

è«‹åš´æ ¼éµå®ˆä»¥ä¸‹èªè¨€è¦å‰‡ï¼š
1. **èªè¨€åŒæ­¥**ï¼šä½¿ç”¨è€…ç”¨ä»€éº¼èªè¨€ï¼Œä½ å°±ç”¨ä»€éº¼èªè¨€å›ç­” (Userèªªè‹±æ–‡å›è‹±æ–‡ï¼Œèªªæ—¥æ–‡å›æ—¥æ–‡)ã€‚
2. è‹¥ä½¿ç”¨è€…èªªä¸­æ–‡ï¼Œé è¨­ä½¿ç”¨ã€Œç¹é«”ä¸­æ–‡ã€ã€‚
3. èªæ°£ä¿æŒæº«æŸ”ã€è‡ªç„¶ã€åƒå¥½æœ‹å‹ä¸€æ¨£ï¼ˆå¤šä½¿ç”¨èªåŠ©è©ã€Œå–”ã€å‘¢ã€å‘€ã€ï¼‰ã€‚
4. å› ç‚ºä½ æ˜¯ä½¿ç”¨ Llama 3 é«˜æ™ºå•†æ¨¡å‹ï¼Œè«‹å±•ç¾å‡ºè°æ˜ä½†è²¼å¿ƒçš„ä¸€é¢ã€‚
"""

# ç”¨ä¾†å„²å­˜å°è©±è¨˜æ†¶
chat_history = []

@app.route("/")
def home():
    return render_template("index.html")

@app.route("/chat", methods=["POST"])
def chat():
    global chat_history
    user_input = request.json.get("message")
    
    if not user_input:
        return jsonify({"response": "è«‹è¼¸å…¥è¨Šæ¯å–”ï¼"})

    # 1. æŠŠä½¿ç”¨è€…çš„è©±åŠ å…¥è¨˜æ†¶
    chat_history.append({'role': 'user', 'content': user_input})

    # 2. æº–å‚™å‚³é€çµ¦ Groq çš„è³‡æ–™ (äººè¨­ + æ­·å²ç´€éŒ„)
    messages_payload = [{'role': 'system', 'content': SYSTEM_PROMPT}] + chat_history

    # é€™è£¡åŸæœ¬æœƒå ±éŒ¯ï¼Œç¾åœ¨åŠ äº† sys.stdout è¨­å®šå¾Œæ‡‰è©²æ²’å•é¡Œäº†
    print(f"â˜ï¸ æš–å¿ƒ (Llama 3.3) æ­£åœ¨æ€è€ƒ... (æ”¶åˆ°: {user_input})")

    if not client:
        return jsonify({"response": "å¾Œç«¯é€£ç·šè¨­å®šæœ‰èª¤ï¼Œè«‹æª¢æŸ¥çµ‚ç«¯æ©ŸéŒ¯èª¤è¨Šæ¯ã€‚"})

    try:
        # 3. å‘¼å«é›²ç«¯ Groq API
        # ä½¿ç”¨ç›®å‰ Groq ä¸Šæœ€å¼·ä¸”å…è²»çš„æ¨¡å‹ï¼šllama-3.3-70b-versatile
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages_payload,
            temperature=0.7, # å‰µæ„åº¦ (0.5~1.0)
            max_tokens=1024, # å›ç­”é•·åº¦é™åˆ¶
            top_p=1,
            stop=None,
            stream=False
        )
        
        # å–å¾— AI å›ç­”
        ai_reply = completion.choices[0].message.content
        
        # 4. å°å‡ºçµæœ
        print(f"âœ… å›æ‡‰ï¼š{ai_reply}")

        # 5. æŠŠ AI çš„å›ç­”ä¹ŸåŠ å…¥è¨˜æ†¶
        chat_history.append({'role': 'assistant', 'content': ai_reply})

        return jsonify({"response": ai_reply})

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return jsonify({"response": "æš–å¿ƒç¾åœ¨é€£ç·šæœ‰é»å•é¡Œï¼Œè«‹æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢ºã€‚"})

if __name__ == "__main__":
    app.run(debug=True, port=5000)